{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "It is a method for reducing the dimensionality of data. It can be thought of as a projection method where data**(A)** with m-columns (features) is projected into a subspace**(B)** with m or fewer columns, whilst retaining the essence of the original data.  \n",
    "  \n",
    "**B = PCA(A)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of Fake data\n",
    "Here we created a fake dataset containing 2 features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "A = array([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "PCA is an operation applied to a dataset, represented by an n Ã— m matrix <b>A</b> that results in a projection of <b>A</b> which we will call **B**. Steps involved for this are mentioned below.  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "The first step is to calculate the mean values of **each column**.  \n",
    "  \n",
    "**M = mean(A)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "M = mean(A, axis=0)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Next, we need to center the values in each column by subtracting the mean column value.  \n",
    "  \n",
    "**C = A - M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2., -2.],\n",
       "       [ 0.,  0.],\n",
       "       [ 2.,  2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A - M\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "The next step is to calculate the covariance matrix of the centered matrix C.  \n",
    "  \n",
    "Covariance is a generalized and unnormalized version of correlation across multiple columns.  \n",
    "  \n",
    "A covariance matrix is a calculation of covariance of a given matrix with covariance scores for every column with every other column, including itself.\n",
    "\n",
    "**V = cov(C)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4.],\n",
       "       [4., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import cov\n",
    "V = cov(C.T)  # We took the transpose to find covariance of columns not rows.\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:\n",
    "Then we calculate the Eigenvalues and Eigenvectors i.e. we do the **Eigendecomposition** of covarience matrix V.  \n",
    "  \n",
    "The eigenvectors represent the directions or components for the reduced subspace of B, whereas the eigenvalues represent the magnitudes for the directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Values:\n",
      "[8. 0.]\n",
      "\n",
      "Eigen Vectors:\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eig\n",
    "eig_val, eig_vec = eig(V)\n",
    "print(\"Eigen Values:\")\n",
    "print(eig_val)\n",
    "print(\"\\nEigen Vectors:\")\n",
    "print(eig_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:\n",
    "The eigenvectors can be sorted by the eigenvalues in descending order to provide a ranking of the components or axes of the new subspace for A. If all eigenvalues have a similar value, then we know that the existing representation may already be reasonably compressed or dense and that the projection may offer little. If there are eigenvalues close to zero, they represent components or axes of B that may be discarded. A total of m or less components must be selected to comprise the chosen subspace. Ideally, we would select k eigenvectors, called principal components, that have the k largest eigenvalues\n",
    "\n",
    "**Important:** Each column in **eig_vec**(above cell) represents 1 eigen vector.  \n",
    "\n",
    "Since the second eigen value is 0, we can discard the second column but lets see what happens if we proceed with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6:\n",
    "Once chosen, data can be projected into the subspace via matrix multiplication.  \n",
    "  \n",
    "**B = eig_vec<sup>T</sup> . C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82842712,  0.        ],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 2.82842712,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import dot\n",
    "B = eig_vec.T.dot(C.T)\n",
    "B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, the second column is 0. That shows we could have rejected it while choosing B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82842712],\n",
       "       [ 0.        ],\n",
       "       [ 2.82842712]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By taking only 1st eigen vector\n",
    "red_eig_vec = eig_vec[:,0]\n",
    "b = red_eig_vec.dot(C.T)\n",
    "b.reshape((-1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
